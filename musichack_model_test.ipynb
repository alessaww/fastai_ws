{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.model import fit\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,bptt = 64,70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing the Music model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/musichack/thesession/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True)\n",
    "FILES = dict(train='wot_train', validation='wot_valid', test='wot_valid')\n",
    "\n",
    "md = LanguageModelData.from_text_files(f'{PATH}', TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "pickle.dump(TEXT, open(f'{PATH}models/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load our saved models in order to test for different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200\n",
    "nh = 500\n",
    "nl = 3\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "    dropout=0.05, dropouth=0.1, dropouti=0.05, dropoute=0.02, wdrop=0.2)\n",
    "# dropout=0.4, dropouth=0.3, dropouti=0.65, dropoute=0.1, wdrop=0.5\n",
    "#                dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam2_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam2_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learner.load_encoder('adam3_5_cyc_6') # this one is a partial learner - during the cyclical training and gives errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_str(s): return TEXT.preprocess(TEXT.tokenize(s))\n",
    "def num_str(s): return TEXT.numericalize([proc_str(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(m, s, l=250):\n",
    "    t = num_str(s)\n",
    "    m[0].bs=1\n",
    "    m.eval()\n",
    "    m.reset()\n",
    "    res,*_ = m(t)\n",
    "    print('...', end='')\n",
    "\n",
    "    for i in range(l):\n",
    "        n=res[-1].topk(2)[1]\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        word = TEXT.vocab.itos[n.data[0]]\n",
    "        print(word.upper(), end='')\n",
    "        if word=='<eos>': break\n",
    "        res,*_ = m(n[0].unsqueeze(0))\n",
    "\n",
    "    m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...K:MAJ|:(3=G,=A,=B,|=C2=C>=D=E>=D=E>=G|=A>=G=A>=B=C2=C>=D|=E>=D=C>=A=G>=E=C>=D|=E>=D=D>=C=D2(3=E=F=G|=C2=C>=D=E>=D=C>=D|=E>=D=C>=A=G>=E=D>=C|=A,>=D=D>=E=F>=G=A>=B|=C2=C>=B=C2:||:(3=G=A=B|=C2=C>=D=C>=B=A>=G|=A>=G=E>=G=A>=G=E>=G|=C2=C>=D=C>=B=A>=G|=A>=G=E>=G=A>=G=E>=G|=C2=C>=D=C>=B=A>=G|=A>=G=E>=G=A>=G=E>=G|=A>=G=A>=B=C>=B=A>=G|=E2=D2=C2:|M:4/4K:MAJ|:=C>=D|=E2=E>=D=E>=D=C>=D|=E>=D=E>=G=A2=G>=E|=C2=C>=D=E>=D=E>=G|=A>=G"
     ]
    }
   ],
   "source": [
    "sample_model(m, \"M:4/4  \",l=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...K:MAJ|:=C2=C2=C2=C2|=B>=C=D>=B=C2=G2|=A>=B=C>=A=G>=F=E>=F|=G>=F=E>=F=D2=G2|=C2=C2=C2=C2|=B>=C=D>=B=C2=G2|=A>=B=C>=A=G>=F=E>=D|=C2=C2=C4:||:=E2=E2=E2=E2|=D>=E=D>=C=B2=B2|=C2=C2=C2=D>=C|=B2=G2=G4|=A2=A2=A2=A2|=G>=A=B>=C=D2=D2|=E>=F=G>=E=F>=E=D>=C|=B2=G2=G4:|M:4/4K:MAJ|:=E2=E2=E2=E2|=D>=E=D>=C=B2=B2|=C2=C2=C2=D>=C|=B2=G2=G4|=A2=A2=A2=A2|=G>=A=B>=A=G2=G2|=A>=B=C>=A=F2=A2|=G2=B2=G4:||:=E2=E2=E2=E"
     ]
    }
   ],
   "source": [
    "sample_model(m, \"M:4/4 k:maj |:(3^g,^a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the input is a short sequence from another databases, from a Queen Song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...=F/4=G/4=A/4=B/4=C'/4|=G=E=C=E=D=C|=D2=D2=E/2=F/2=G/2=A/2|=G2=E2=E=D|=C2=C2=C/2=D/2=E/2=F/2|=G2=G2=G=A|=G2=G2=C/2=D/2=E/2=F/2|=G2=G2=G=E|=F2=F2=E=D|=E2=E=D=C=B|=C2=C2|M:3/4K:MAJ|:=C>=D|=E2=E2=E>=D|=E2=E2=E>=D|=C2=C2=C>=D|=E2=E2=E>=D|=C2=C2=C>=D|=E2=E2=E>=D|=C2=C2=C2|=C4:||:=E>=F|=G2=G2=C>=D|=E2=E2=D>=E|=F2=F2=A>=F|=G2=E2=C>=D|=E2=E2=E>=D|=C2=C2=C>=D|=E2=E2=D>=C|=C4:|M:3/4K:MAJ|:=C>=D|=E2=E2=E>=D|=E2=E2=E>=D|=C"
     ]
    }
   ],
   "source": [
    "sample_model(m, \"_b/2=e/2-_d/2-A/2-=B,/2-A,/2-A,,/2-=B,,,/2-A,,,/2-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
